#+title: Benchmarking for Optimistic Order-Preserving Hash Join (OOHJ)

#+BEGIN_QUOTE
[!WARNING]
This software is /not/ intended for production use and is intended for our own private research purposes. Although others may use the code, please be aware that it is prone to change without notice.
#+END_QUOTE

This repository is part of our Master's thesis, focused on benchmarking modifications made to MySQL. Our fork of MySQL, which implements the Optimistic Order-Preserving Hash Join (OOHJ) feature, is available at: https://github.com/johansolbakken/mysql-server/tree/oohj/oohj-iterator.

Link to Master Thesis will be added later.

* Requirements

#+begin_src
brew install ruby
gem install pq_query
brew install hyperfine
#+END_SRC

* Quick start

- Requires MySQL running and config.yaml set up pointing at a mysql executable and server.

#+begin_src
ruby bin/download.rb                                    # downloads csv files with JOB dataset
make fresh                                              # setup, feed, prepare
ruby bin/benchmark.rb --run ./job/6a.sql --analyze      # EXPLAIN ANALYZE on query 6a
#+end_src

* Testing the Optimistic Hash Join

1. Start the MySQL server
2. Fill out config.yaml

#+begin_src shell
make test
#+end_src

This will compare .sql files in homemade_dataset folder against .expected files in homemade_dataset folder. It will also do other types tests defined in tests.yaml file.

These tests are passing under our current assumptions. As we improve optimistic order-preserving hash join these tests will fail and we need to take new snapshots of the new expected state.

* Homemade Sorting and Hash Join Dataset

To generate the data:

#+begin_src shell
ruby ./bin/generate_sort_hashjoin_dataset.rb 10 10
#+end_src

Always remember to prepare the env before running queries:

#+begin_src shell
make prepare
#+end_src

Then you can run the following sql:

#+begin_src sql
use test_sort_hashjoin_db;
EXPLAIN FORMAT=tree select * from table_b, table_a WHERE table_b.a_id = table_a.id ORDER BY table_a.id;
#+end_src

This generates lets us propose optimistic hash joins since ordering_state gets set.

Since the JOB dataset does not include any ORDER BY or DISTINCT, it did not make any interesting order in MySQL. This was experimentally proven by checking for an ordering that was followed every time optimistic hash join was proposed. Therefoer we created this dataset which we can build our own queries around and also scale the dataset using the generate script.

* Commands

** Download JOB dataset

#+begin_src shell
make job-dataset
#+end_src

** Start MySQL

1. Download and build the MySQL source code.
2. Start MySQL using MySQL Test Run (MTR), MySQL's testing script:

First-time setup:

#+begin_src shell
cd build # Navigate to the MySQL build folder
./mysql-test/mtr --start
#+end_src

For subsequent runs, use:

#+begin_src shell
./mysql-test/mtr --start-dirty
#+end_src

3. Configure the path to the MySQL binary in `config.yaml` (e.g., `build/bin/mysql`).

** config.yaml

Copy the `config.yaml.example` file to `config.yaml` and update it with the path to your MySQL binary.

It is important that /path/ points to a mysql client executable.

** Setup the Database

Then, initialize the database by creating tables and indexes:

#+begin_src shell
make setup
#+end_src

** Load the Data

Feed the downloaded dataset into the database:

#+begin_src shell
ruby bin/benchmark.rb --feed
#+end_src

** Prepare MySQL environment

This command sets the environment to ensure the environment is the same for every test.

#+begin_src shell
ruby bin/benchmark.rb --prepare-mysql
#+end_src

** Run SQL Queries

To run SQL queries, use the following commands:

- Execute a query:
#+begin_src shell
ruby bin/benchmark.rb --run ./job/1a.sql
#+end_src

- Execute a query with EXPLAIN ANALYZE to analyze execution:
#+begin_src shell
ruby bin/benchmark.rb --run ./job/1a.sql --analyze
#+end_src

- Execute a query with EXPLAIN FORMAT=TREE to analyze plan:
#+begin_src shell
ruby bin/benchmark.rb --run ./job/1a.sql --tree
#+end_src

* Cleanup JOB files

To clean up the database and remove generated artifacts, run:

#+begin_src shell
ruby bin/cleanup.rb
#+end_src

* tests.yaml

The YAML configuration is structured under a top-level =tests= key that divides tests into two categories: *diff_test* and *contain_test*. Each category may include a global =setup= section to prepare the environment before running tests, followed by a list of test cases under the =tests= key. In *diff_test*, each test is defined with a =name=, an SQL file specified by the =sql= key, and an =expected= file for output comparison; tests can also have individual /setup/ commands. In *contain_test*, tests may include individual =setup= commands and verify outputs by checking for specific substrings using a =contains= list. To add a new test, choose the appropriate category based on whether you want a full output comparison or substring validation. Then, include any necessary setup commands and define the test with a unique =name=, the path to the SQL file, and either an =expected= file (for *diff_test*) or a =contains= list (for *contain_test*). Note that tests run /sequentially/, so the environment setup for one test may affect subsequent tests.

#+begin_src yaml
tests:
  diff_test:
    setup:
      - "ruby ./bin/generate_sort_hashjoin_dataset.rb 10000 10000"
      - "ruby ./bin/benchmark.rb --prepare-mysql"
    tests:
      - name: "Basic test"
        sql: "./homemade_dataset/homemade.sql"
        expected: "./homemade_dataset/homemade.expected"
      - name: "Disable optimistic hash join"
        sql: "./homemade_dataset/homemade_disabled.sql"
        expected: "./homemade_dataset/homemade_disabled.expected"

  contain_test:
    # Global setup is optional here.
    tests:
      - name: "went_on_disk=false, n=100 m=100"
        setup:
          - "ruby ./bin/generate_sort_hashjoin_dataset.rb 100 100"
          - "ruby ./bin/benchmark.rb --prepare-mysql"
        sql: "./homemade_dataset/went_on_disk.sql"
        contains:
          - "(optimistic hash join!)"
          - "(went_on_disk=false)"
#+end_src

* C++ Debugging Tools

** Header-only Logging File

The =debug/logger.h=  is a class that can be used to fast log to a file.

Usage:

#+begin_src c++
#include "/absolute_path_to_benchmark/debug/logger.h"

static Logger* s_logger = nullptr;

ClassToTest::ClassToTest() {
    s_logger = new Logger("~/path_to_output/log.txt");
}

void ClassToTest::functionToTest() {
    // Lets write CSV information to the logger.
    auto& logger = *s_logger;

    while (someCondition) {
        logger << logger.timestamp() << "," this->getSomeValue() << ",";
        logger << this->getState() << "\n";
    }
}

#+end_src

This class will delete the log-file on construction.

There is a =timestamp()= function for getting timestamps easily.

Currently using streams.

* Generate TPC-H for MacOS

#+begin_src shell
podman run --rm -it \
  -v $(pwd):/src \
  -w /src \
  ubuntu:22.04 \
  bash
# now in podman ubuntu
sudo apt update && sudo apt install -y gcc make ruby bison flex
ruby bin/build-tpc-h.rb
#+end_src

This will generate folders:
- =tpc-h-queries=
- =tpc-h-ddl=
- =tpc-h-dataset=

* Generate TPC-DS for MacOS

#+begin_src shell
# copy the Makefile.suite and add -fcommon to CFLAGS
CFLAGS = $(BASE_CFLAGS) -D$(OS) $($(OS)_CFLAGS) -fcommon

# Start podman
podman run --rm -it \
  -v $(pwd):/src \
  -w /src \
  ubuntu:22.04 \
  bash

# now in podman ubuntu
sudo apt update && sudo apt install -y gcc make ruby bison flex
ruby bin/build-tpc-ds.rb
#+end_src

* Join Order Benchmark Commands

** Download job dataset

Creates job-dataset folder.

#+begin_src shell
make job-dataset
#+end_src

** Setup database and indexes in MySQL

Requires MySQL to be running.

#+begin_src shell
ruby bin/setup-job.rb
#+end_src

To wipe database and recreate:

#+begin_src shell
ruby bin/setup-job-rb --force
#+end_src

* Make Console

Easy setup. Requires the mysql server to be running.

#+begin_src shell
make console
#+END_SRC
